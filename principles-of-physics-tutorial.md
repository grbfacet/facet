---
layout: default
title: Tutorial - principles of physics
pagetype: tutorial
---

### Overview

In this tutorial we discuss the outlook and approach of modern physics, physics since roughly Newton. We look at methods and practices of physics as a science. Other tutorials delve into various specific physics subjects. 



### The terms “classical”, “quantum” and “modern” as used by physicists:

The term “classical” as in “classical physics” or “classical mechanics” or “classical electrodynamics” or “classical statistical mechanics” or many other uses is contrasted with the term “quantum” as in “quantum physics” or “quantum mechanics” or “quantum electrodynamics” or “quantum statistical mechanics”. This usage has a precisely understood meaning among physicists. Classical physics is all of physics that does not require consideration of quantum effects. Quantum effects are generally only noticeable when we are dealing with very tiny energy effects on the level of atomic phenomena. The term “classical” does not refer to a historical era although its etymological origin is related to a historical reference. Even today, there are new discoveries in many areas of classical physics. The revolutionary Einstein theories of relativity and gravitation are part of classical physics since quantum effects are not part of those theories. 

In western culture at large, “classical” as a historical term refers to the Greco-Roman era two millennia ago. In western culture at large the term “modern” has a multitude of historical period references. Perhaps a good example of the confusion possible about this adjective is when we consider that the modernist period in English literature ended sometime before World War II, followed by the post-modernist period which also has had its zenith and is essentially over today. In other uses in western culture, the term “modern” often refers generally to a time that began with the Renaissance, creating the three western periods classical, medieval and modern. In physics the term “modern” is also used in contradictory ways but one important usage is when it is said that modern physics began with Newton. 

### Calculus and modern physics

Although we will use very little calculus in this physics tutorial it will be helpful to understand what calculus, invented by Newton, did for physics. Newton’s calculus is the mathematics of change and accumulation. Modern physics began with Newton’s invention of calculus. From, at least, the time of the ancient Greeks, people have tried to understand change but until there was a mathematical tool available to describe change quantitatively, the study of change was essentially limited. 

One could concoct any manner of explanation for change, or a more specific form of change, motion, but without the ability to make numeric predictions, one was left with only trying to demonstrate the logic and consistency of a theory in a qualitative way. Newton changed all that with his invention of differential and integral calculus. Differential calculus is the mathematics of change, more specifically, rate of change and integral calculus is the mathematics of accumulation, or again, accumulation relative to some amount of change. 

Some important points are implied in these two paragraphs. Suppose someone said something changed by 5 feet or 5 dollars or 5 seconds or 5 gallons. Implicit in change is a starting point and an end point, i.e., change is always relative to two events, a beginning event or place and an ending event or place. It is 5 miles from town A to town B. The stock price increased 5 dollars from Feb 1 to March 1. It took 5 years to transform the grapes from ripe on the vine to the wine in our glass. It took 5 gallons of gas to make the trip from Los Angeles to San Diego. 

When the two points of reference differ by some kind of quantitative measure we can talk about a rate of change. If it took 10 minutes to drive the 5 miles from A to B we had an average rate of location change (speed) of 5 miles per 10 minutes or 30 mile per hour. If the stock started at 100 dollars per share, then it increased 5% in one month or 60% a year. In the case of the grapes to wine there is no quantitative measure of the difference between grapes on the vine and wine in the glass so there is no quantitative rate of change involved. The distance covered with the 5 gallons of gas depends on exactly where in LA you leave and where in San Diego you arrive. Let’s just say the trip was 100 miles. Then the rate of gas usage was 0.05 gallons per mile or more commonly we invert the ratio and say 20 miles per gallon. 

Let’s look at the idea of accumulation. If something has a rate of change, 30 mph, 60% per year, or 20 miles per gallon we can apply that over a specific amount of the denominator quantity. If we drive at 30 miles per hour and we do that for six hours we accumulate 180 miles traveled. If we hold the stock for three years at a rate of increase of 60% per year the stock will accumulate an increase of 180% (we ignore compounding here). If we want to travel (accumulate) 400 miles at a gas usage rate of 20 mpg it will take 20 gallons of gas. If gas sells at the rate of $3.00 per gallon we will accumulate a gas cost of $60 for our 400 mile trip. 

##### Change and accumulation 

Rate of change and accumulation are two sides of the same coin, if you have one, you have the other. This is what’s known as the fundamental theorem of calculus, that differential calculus is the inverse of integral calculus. Let’s talk about calculus. In the examples we have given, we might call them difference calculations, calculations based on a constant rate of change over a fixed amount of change. For example 30 mph was a rate of change and if we applied it over 3 hours we would cover 90 miles. But in real life a car’s speed is constantly changing, a stock price is moving up and down at a changing rate and even our gas mileage varies somewhat with driving conditions which is exemplified in the citation of city and highway gas usage rates provided on all new car stickers. 

In fact, new cars now have a gauge that tells you the “instantaneous” mpg. If we tromp on the accelerator leaving a stop sign, our gas mileage rate might be quite low, say 10 mpg in a car that normally averages 35 mpg. On the other hand if we are speeding down the freeway or going down a long hill and take our foot off the accelerator we will typically see 99.9 mpg, usually the biggest number the gauge can show. In fact, if we put the car in neutral and turn off the engine and coast, our rate is actually infinite since we are covering distance without using any gas at all.  

These are examples of change and accumulation taken from familiar daily life. What are some examples taken from the world of physics, the study of change in the world of matter? The motions of objects like planets, gyroscopes, vibrating guitar strings, sound waves, the flow of air over a plane wing or the flow of fluid in a pipe are examples that are all explained by Newton’s laws of force and motion. The amount of heat it takes to boil water, i.e., the amount of heat to raise the temperature a certain number of degrees, the amount of disorder (entropy) increase in a chemical reaction, the atmospheric temperature change of a parcel of moist air rising after being heated by the hot ground on a sunny day, and many other examples are explained by the theory of thermodynamics. The rate of battery discharge in a laptop is explained in electromagnetic theory. 

Notice all these examples from modern physics involve quantitative rates of change and accumulation and hence require the use of differential and integral calculus. None of this is possible without Newton’s invention. Leibniz is also credited with inventing the calculus and we won’t go into that controversial bit of history. We simply side with Newton because the scientific tradition of applying the calculus to problems of science indisputably begins with Newton. If we were primarily interested in the mathematics and philosophy of infinitesimals instead of physics we would put emphasis on Leibniz’s contributions to understanding the mathematical theory of the calculus. For Newton calculus was simply a tool to get on with physics. For Leibniz, calculus was a philosophical and mathematical idea in its own right.

##### Instantaneous rate of change 

What Newton did was work out the mathematics of instantaneous rate of change, differential calculus, and the mathematics of accumulation of a quantity whose rate of change varies from instant to instant, integral calculus. What is an instantaneous rate of change? It is thought of as the limit of a smaller and smaller amount of change. We can measure the average change of a stock price over each year, over each month, over each day, over each hour, minute or second. In fact some computer trading programs work on price changes measured in thousandths of a second. We can imagine a similar limiting process for the speed of a car or anything else that has change that can be measured with numbers. 

Let’s look at what Newton is perhaps most famous for, the combination of his laws of motion with his theory of gravity which he successfully applied to predicting the motion of planets. His theory of motion is: forces cause _changes_ of uniform motion, where "uniform" means constant speed in a straight line. This idea contrasts with Aristotle’s idea that forces cause uniform motion itself. According to Aristotle, the shot arrow moves steadily through the air because the air somehow keeps pushing it along. There is a long and fascinating history from Aristotle to Newton with Galileo playing a crucial role in recognizing that a body in motion has inertia and simply keeps moving in a straight line at the same speed without any force being applied. Galileo's idea is now known as Newton’s first law of motion. 

Without going into the history we should be careful not to disparage the ideas of the ancients. For example, consider a horse pulling a cart, something very familiar to Aristotle. The horse pulls with a constant force and the cart moves at a constant speed. If the horse pulls harder, the cart moves at a faster speed, so obviously speed is proportional to force. But Newton says the force causes a change of the speed, he says the force does not cause the speed itself. In our modern point of view the cart does indeed move with a speed proportional to the pull of the horse, but it also is affected by other forces, in particular the force of friction in its wheel bearings and all the small bumps in the road. Newton would say those forces resisting the motion exactly balance the pull of the horse and the cart moves at a constant speed because the total of all forces on it balance out to zero. 

However, the ancients noticed steady motion without any apparent force in the heavens where the sun, moon, planets and stars moved across the sky at a steady speed with nothing pushing them. But another of Newton’s great accomplishments was to assert that the laws of motion on the earth were the same as those in the heavens whereas it is obvious to common sense that the sky is an entirely different kind of place than around the surface of the earth. So Newton unified many different phenomena under one set of laws. 

Newton gave a quantitative law of gravity. Not just that the gravity of the earth pulled objects to it but he said quantitatively how strong the pull was. The further you go from the earth into space the weaker the force. In particular, he said, the force gets weaker as the square of the distance. If the force is a certain amount at 100,000 miles from the earth then it will be four times as weak at twice the distance, 200,000 miles and nine times as weak at three times the distance, 300,000 miles. 

From a mathematical point of view the force could have had any kind of relation to the separation distance. You could write a mathematical formula for the force being stronger with distance. For example the force, F, goes as d, the distance. With this formula, launching objects into space would be impossible because as they get further from the earth the rockets have to push even harder to keep going and eventually, they run out of fuel and fall back. (There actually is a force that gets stronger as the attracting objects get further apart, the strong force, the force between quarks in protons and neutrons. That is the reason we can never isolate a single quark.) Or the force could go as the inverse of the distance, if the force is a certain amount at 100,000 miles, it would half that at 200,000 miles and a third at 300,000 miles. Compare this to Newton's inverse square force formula mentioned above where at 300,000 miles the force is one ninth what it was at 100,000 miles.

There are even more appalling possibilities. Suppose the force varied as the inverse square of distance for 100,000 miles then varied as the inverse cube for some further distance then became proportional to distance for a while, etc. Or suppose the force varied with time growing stronger and weaker cyclically. Even Newton would have been stumped by these scenarios. That is one of the great mysteries and beauties of nature, that it follows rules at all and that the rules are actually fairly simple to understand once we figure them out. 

As you can see, all the different possible gravity force laws predict different forces at different distances and we can simply watch how objects move around the earth and the sun to see which force law gives a prediction that agrees with what we see in nature and then we say, that is the true force law for gravity. This is exactly what Newton did but to do it he needed his calculus. Aristotle could not have tested these different force laws very easily since he didn’t have calculus.

Let’s look at Newton’s monumental motion law, the second law that says a force produces a change of speed and the change in speed is proportional to the force. It could be that the change of speed is proportional to the force squared or that force squares the speed or cubes it or any other possible mathematical relationship. An infinite number of force laws are mathematically possible but the aim is to find the law that matches reality. Let’s consider the gravity force acting on an object near the earth’s surface. We won’t show why but when you calculate the force of gravity using the inverse square of the distance law, the distance to be used is the distance of the object from the center of the earth, not from the surface of the earth. 

For an object just a few feet above the surface we calculate the force based on the fact that the object is about 4000 miles from the center of the earth not based on a few feet. Now suppose we are interested in the motion of an object dropped out of a helicopter hovering two miles in the air. As it falls two miles the force of gravity on it will be a tiny bit stronger when it reaches the last, say, one foot from the ground. It would be the difference between the inverse square of 4002 miles and 4000 miles. This is a very small difference so we usually just say the force of gravity near the earth’s surface is the same at any point above the surface but within a few miles. If we were doing a very precise measurement we would need to calculate with a changing strength of the force as we got closer to the earth and notice the words, “change of force”, and that should tell us that to do the problem right it will require the mathematics of change, calculus! 

It turns out that Earth’s gravity near the surface changes the speed of an object by about 10 meters per second every second the object is falling. (Notice 10 meters per second is a speed and we are saying how much the speed changes per second due to the force of gravity which we have approximated as constant near the surface.) If we drop the object out of the hovering chopper, in the first second it is falling, it will go from a speed of zero to a speed of 10 meters per second. In the next second it is falling, it will speed up another 10 meters per second. It ends its first second of fall moving 10 m/s and by the end of the next second it has gained another 10 m/s so it is moving at 20 m/s. Another second of fall will add another 10 m/s to its speed and after three seconds it will be moving at 30 m/s. After ten seconds of falling it will be moving 100 m/s. Notice, we've derived

<span class="eq">s = gt, where s is speed, g is the acceleration of gravity and t is time of fall.</span>

We were able to do this pretty directly because we have approximated g as a constant, it does not change with distance fallen.

But suppose we want to know how far the object falls in one or two or ten seconds? If it was falling at a steady speed we can easily do the math, but its speed is constantly changing, constantly increasing. How do we calculate the distance it falls? This is a question of accumulation, integral calculus: accumulation of distance over a period of time with a non-constant speed (steadily increasing in this case). We want to integrate, add together, the amount of distance traveled over the whole time. We could imagine approximating an answer by saying in the first second it averaged 5 m/s so it fell 5 meters. In the next second it fell at an average of 15 m/s so it fell another 15 meters during the 2nd second. Add that to the 5 meters for the first second and it has now fallen 20 meters in two seconds. In the third second it averages 25 m/s so it falls another 25 meters for a total of 45 meters after three seconds. If we keep doing the math we get the sequence 

<span class="eq">1-5,</span>

<span class="eq">2-20,</span>

<span class="eq">3-45,</span>

<span class="eq">4-80,</span>

<span class="eq">5-125,</span>

<span class="eq">6-180,</span>

<span class="eq">7-245,</span>

<span class="eq">8-320,</span>

<span class="eq">...,</span>

If you’re Newton and you are playing around with numbers like this you might notice if you take the first number in the pair, the total seconds falling number, and square it and divide by two and multiply by the acceleration of gravity (10 m/s per second) you get the second number! That is you would have discovered 

<span class="eq">d = 1/2gt<sup>2</sup>, where g = 10 m/sec per second.</span>
 

We started with s, speed, 

<span class="eq">s = gt and we “integrated” that formula over time.</span>

If we were Newton, we might have wondered about integrating the new formula involving 1/2gt<sup>2</sup> over time and we would find we get the result 

<span class="eq">1/3 x 1/2gt<sup>3</sup> and if we integrated that we would get</span>

<span class="eq">1/4 x 1/3 x 1/2gt<sup>4</sup>.</span>


We would have found that the integral of gt<sup>n</sup> over t is 

<span class="eq">1/(n+1)gt<sup>n+1</sup>.</span>

Differentiation is going the opposite direction. Just from a mathematical point of view, if you have a formula for the accumulation of distance and you want to know how fast you are accumulating you go the opposite way. If you accumulate kx<sup>n</sup> after x units of total accumulation, then at that moment you are accumulating at the rate of 

<span class="eq">nkx<sup>n-1</sup>.</span>

Newton’s achievements in physics were staggering but without his achievement of the calculus, none of what we know as physics today would have been possible because physics, the laws governing the material world, almost always involve relations between changing and accumulating variables. And that is calculus. 

It is interesting to note that Archimedes actually developed the beginnings of integral calculus. Two events buried Archimedes' great discovery, his killing by a Roman soldier and the predominance that was given over time to Aristotle’s ideas. Aristotle had theories about everything but Archimedes only focused on basic inanimate natural phenomena and was seen as a narrow specialist and posterity mistakenly accepted Aristotle’s judgment over Archimedes. The reason for this was probably that Aristotle was a generalist and tried to come up with a consistent logical theory of everything. Today we tend the other way and compartmentalize knowledge. 



### Theories and measurement errors: 

In the relativity tutorial we will discuss Einstein's Relativity Theory which improved Newton's theory of motion. When this transition from Newton to Einstein is normally described it is referred to as Einstein disproving Newton's theory. We take the view that Einstein improved Newton's theory in the sense that Newton's theory turned out to be only an approximation to a more inclusive theory. This brings up the crucial role of measurement error in experimental science. A quantitative theory is used to make a numerical prediction about what will happen in a particular situation. The prediction is normally a number that can be measured. Let’s say the theory predicts 2.7 inches and a series of measurements are made and the result is a series of numbers like 

<span class="eq">2.73, 2.65, 2.79, 2.69 … </span>

The numbers are all close to the predicted 2.7 and they have an average near to 2.7. Now, we ask the big question. Did the experiment confirm or disprove the theory? 

The answer, “confirms” or “disproves”, depends on how we account for the discrepancy between the measured values and the predicted value. We always expect errors when the variable is a real number, as opposed say to an integer, because measurement is never exact. But the more specific question is “how big do we expect the measurement errors to be?” Using our eyes and a standard 12 inch ruler we might expect to be able to measure to a precision [link to precision, accuracy, random errors, systematic errors] of something like a tenth of an inch. Suppose the theory predicted 2.7 inches but the theory is actually only an approximation to a better theory and the better theory predicts 2.69 inches. We will never "disprove" the first theory when our measurement precision is only a tenth of an inch and the difference between the two theories’ predictions is only one hundredth of an inch. To disprove the first theory we must perform measurements with precision below hundredths of an inch. Thus, in our example 2.7 inch test, the measurements did not and could not, for lack of adequate precision, disconfirm the old theory but we would say they are consistent with the old theory.

On the other hand, there is a strong sense in which the old theory is completely wrong and the new theory is “right” until the newer one is displaced by some even newer theory yet to be discovered. Perhaps we should more accurately describe this series of theories with the word “better”. Each succeeding theory is better than the last one. It is better because it correctly describes a wider range of situations than the previous theory. So what are we talking about here? A physics theory is typically a set of principles or laws. These are general statements, e.g., energy is conserved or the speed of light will always be measured to be the same in any frame of reference moving with constant velocity relative to any other frame of reference where it is measured. In two theories, one better than the last, the general statements clearly contradict each other and it is logically impossible that both are true. But what does true mean? 

For example, in the discussion of relativity below we will compare the earlier Newton theory with Einstein’s and we will see that at speeds well below the speed of light the formula for the particle energy for both theories are the same within the measurement error of the 19th century. There were no cases of relativistic speed phenomena available to measure that could be mesured with sufficient precision with the technology of the era, so there was no direct indication of anything wrong with Newton. However, there was indirect evidence accumulating after the 1860s, but it was not understood until Einstein’s theory. In fact, his theory was not motivated by measurements of high speed particles. Within the range of physical phenomena available to study until the late 1890s, one could not distinguish the two theories. The predictions would have been the same within measurement error if someone had proposed relativity that early. But the principles behind the two theories flat out contradicted each other. Einstein said the inertial mass of an object changed with its speed and Newton said it stayed the same. Yet at low speeds these different principles lead to the same quantitative formula as we will see below. 

We apply theories to specific situations when we make a measurement. Newton’s theory of gravity says all bodies with mass attract each other with a certain mathematically defined amount of force. But when we test that theory we apply it to individual situations: an apple falling to the ground, the moon revolving around the earth, the earth revolving around the sun, a rocket capsule sent to Mars. In each specific situation Newton’s theory can be used to calculate the motions and we can then actually measure the motions and compare the theory based prediction with the actual observed (measured) motions. Once we take into account the limits of our measurements’ precision we reach the conclusion that either the measurements do or don’t agree with the theory to within those measurements' precision limits.  

A related consideration applies when two theories differ significantly only in more extreme conditions. Newtonian and relativity physics only show significant differences in their predictions when we are dealing with objects with speeds near the speed of light. Cars, planes, rockets, bullets, even meteors, planets and stars move at much less than a thousandth the speed of light and the relativistic effects for those are only noticeable with very precise measurements. 

##### Precision, accuracy, random errors and systematic errors

In the erergy doubling experiment, it was not essential to precisely measure the electrons' energies. In general, development of plasma acceleration technology did not usually require careful attention to exacting measurement standards. Nevertheless, it is helpful to understand the relevant error concepts because quantitative numerical measurements are crucial to the progress of physics and are crucial to the progress of any study that involves numerical measurements. 

Precision and accuracy have different meanings. The _accuracy_ of a measurement concerns how close the measurement result is to the true value. The _precision_ of a measurement concerns the amount of error in the measurement itself regardless of how close it is to the true value. Suppose we are measuring how long to cut some 2x4 boards for horizontal bracing between vertical 2x4s in a wall where, for some reason, the space between the vertical pieces varies from place to place. We measure the gap at one location and carefully mark out that length on a board and cut it. And, “rats”, it is too long to fit between the vertical boards. It is off almost 2 inches, yet we made the mark of where to saw with a precision of 1/16”. We were very careful about that. Unfortunately we realize that when we measured the gap between the two verticals we measured from the left edge of one vertical board to the left edge of the next vertical board rather than measuring the space in between the right edge of one and the left edge of the other. We made a precise but inaccurate measurement of the gap. 

These considerations lead to the concept of errors of measurement. We generally distinguish two kinds of errors called systematic and random. A _systematic error_ is one that recurs in every measurement and is the same amount. In our board sawing example, if we had measured all the gaps first and then sawed all the braces before trying to put any of them in place we would have made the same systematic error every time when we measured each gap from left edge to left edge. Every gap would have had the same extra length in it, namely, the thickness of one vertical board, nominally 2 inches for a standard 2x4 board. 

Suppose we have a different task, to cut many braces all the same length. We measure, accurately this time, and mark and cut over and over. Then we lay all our braces side by side and discover they are not all exactly the same length. They vary “_randomly_” in length by varying small amounts due to the imprecision of our marking and sawing. In this case if we made very accurate measurements of each cut brace piece and plotted them in a histogram graph we would find they followed the famous Gaussian Bell curve where many are close in length to a central average but fewer and fewer have increasing _random_ errors “in the tails of the distribution”. The Bell curve is very symmetric with its average, its maximum and its modal value all being the same. There are other patterns of random distributions depending on the type of situation such as the Poisson, which models things like the number of calls per minute to some place, like the U.S. IRS, that gets lots of phone calls every day. The Poisson is skewed, steeper on the side close to zero frequency and with a long tail out beyond the point of maximum frequency. In a Poisson distribution the average, the maximum and the modal values are all different from each other. 


